{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "Accuracy: 0.81\n",
      "Precision: 0.78\n",
      "Recall: 0.81\n",
      "F1: 0.73\n",
      "        pred:0  pred:1\n",
      "true:0    8111      60\n",
      "true:1    1917     111\n",
      "Baseline model cross-validation scores:  [0.7277403  0.73363266 0.73118051 0.73983332 0.73237477]\n",
      "Baseline model mean cross-validation score:  0.7329523124686068\n"
     ]
    }
   ],
   "source": [
    "# Vorhersagen auf dem Testdatensatz\n",
    "y_pred = rf_classifier_baseline.predict(X_test)\n",
    "\n",
    "# Bewertung des Modells\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "\n",
    "print(f\"Baseline Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "\n",
    "unique_label = np.unique([y_test, y_pred])\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=unique_label),\n",
    "    index=[\"true:{:}\".format(x) for x in unique_label],\n",
    "    columns=[\"pred:{:}\".format(x) for x in unique_label],\n",
    ")\n",
    "print(cmtx)\n",
    "\n",
    "# Perform cross-validation on the training set using precision as the scoring metric\n",
    "cv_scores = cross_val_score(\n",
    "    rf_classifier_baseline, X_test, y_test, cv=5, scoring=\"f1_weighted\"\n",
    ")\n",
    "\n",
    "# Print out the cross-validation scores\n",
    "print(\"Baseline model cross-validation scores: \", cv_scores)\n",
    "print(\"Baseline model mean cross-validation score: \", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Costs and predict new values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Different Classifiers\n",
    "# Leaving out unimportant features\n",
    "\n",
    "\n",
    "# Initialisierung und Training des Random Forest Classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [30, 100, 300, 1000],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 10, None],\n",
    "    \"max_depth\": [3, 6, 8, 10],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_weighted\",\n",
    ")\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1-Score:  0.7466455563434087\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimator\n",
    "clf_best = CV_rfc.best_estimator_\n",
    "# Predict the target on the test data\n",
    "predictions = clf_best.predict(X_test)\n",
    "# Print Precision\n",
    "print(\"Test F1-Score: \", f1_score(y_test, predictions, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "Accuracy: 0.81\n",
      "Precision: 0.77\n",
      "Recall: 0.81\n",
      "F1: 0.75\n",
      "        pred:0  pred:1\n",
      "true:0    8036     135\n",
      "true:1    1833     195\n",
      "Baseline model cross-validation scores:  [0.73535383 0.74351361 0.74327974 0.74226491 0.74390893]\n",
      "Baseline model mean cross-validation score:  0.7416642021734474\n"
     ]
    }
   ],
   "source": [
    "# Vorhersagen auf dem Testdatensatz\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "# Bewertung des Modells\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "\n",
    "print(f\"Baseline Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "\n",
    "unique_label = np.unique([y_test, y_pred])\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=unique_label),\n",
    "    index=[\"true:{:}\".format(x) for x in unique_label],\n",
    "    columns=[\"pred:{:}\".format(x) for x in unique_label],\n",
    ")\n",
    "print(cmtx)\n",
    "\n",
    "# Perform cross-validation on the training set using precision as the scoring metric\n",
    "cv_scores = cross_val_score(\n",
    "    clf_best, X_test, y_test, cv=5, scoring=\"f1_weighted\"\n",
    ")\n",
    "\n",
    "# Print out the cross-validation scores\n",
    "print(\"Baseline model cross-validation scores: \", cv_scores)\n",
    "print(\"Baseline model mean cross-validation score: \", np.mean(cv_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
