{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, RandomUnderSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3D_secured</th>\n",
       "      <th>CARD_Diners</th>\n",
       "      <th>CARD_Master</th>\n",
       "      <th>CARD_Visa</th>\n",
       "      <th>Day of Month</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>PSP_Goldcard</th>\n",
       "      <th>PSP_Moneycard</th>\n",
       "      <th>PSP_Simplecard</th>\n",
       "      <th>PSP_UK_Card</th>\n",
       "      <th>Time of Day</th>\n",
       "      <th>amount</th>\n",
       "      <th>previous_attemps</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   3D_secured  CARD_Diners  CARD_Master  CARD_Visa  Day of Month  Day of Week  \\\n",
       "0           0            0            0          1             1            5   \n",
       "1           0            0            0          1             1            5   \n",
       "2           1            1            0          0             1            5   \n",
       "\n",
       "   PSP_Goldcard  PSP_Moneycard  PSP_Simplecard  PSP_UK_Card  Time of Day  \\\n",
       "0             0              0               0            1            0   \n",
       "1             0              0               0            1            0   \n",
       "2             0              0               0            1            0   \n",
       "\n",
       "   amount  previous_attemps  success  \n",
       "0      89                 0        0  \n",
       "1      89                 1        1  \n",
       "2     238                 0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/transformed_data.csv\", index_col=0)\n",
    "df = df.sort_index(axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['3D_secured', 'CARD_Diners', 'CARD_Master', 'CARD_Visa', 'Day of Month',\n",
      "       'Day of Week', 'PSP_Goldcard', 'PSP_Moneycard', 'PSP_Simplecard',\n",
      "       'PSP_UK_Card', 'Time of Day', 'amount', 'previous_attemps'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Auswahl Features und Zielvariable\n",
    "zielvariable = \"success\"\n",
    "features = df.columns.drop(zielvariable)\n",
    "print(features)\n",
    "X = df[features]\n",
    "y = df[zielvariable]\n",
    "\n",
    "# # Aufteilung der Daten in Trainings- und Testdatens√§tze\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, max_features=10, n_estimators=500,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=8, max_features=10, n_estimators=500,\n",
       "                       random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_features=10, n_estimators=500,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier_baseline = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_features=10,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_classifier_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics:\n",
      "Accuracy: 0.81\n",
      "Precision: 0.78\n",
      "Recall: 0.81\n",
      "F1: 0.73\n",
      "        pred:0  pred:1\n",
      "true:0    8111      60\n",
      "true:1    1917     111\n",
      "Baseline model cross-validation scores:  [0.7277403  0.73363266 0.73118051 0.73983332 0.73237477]\n",
      "Baseline model mean cross-validation score:  0.7329523124686068\n"
     ]
    }
   ],
   "source": [
    "# Vorhersagen auf dem Testdatensatz\n",
    "y_pred = rf_classifier_baseline.predict(X_test)\n",
    "\n",
    "# Bewertung des Modells\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1, average=\"weighted\")\n",
    "\n",
    "print(f\"Baseline Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")\n",
    "\n",
    "\n",
    "unique_label = np.unique([y_test, y_pred])\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=unique_label),\n",
    "    index=[\"true:{:}\".format(x) for x in unique_label],\n",
    "    columns=[\"pred:{:}\".format(x) for x in unique_label],\n",
    ")\n",
    "print(cmtx)\n",
    "\n",
    "# Perform cross-validation on the training set using precision as the scoring metric\n",
    "cv_scores = cross_val_score(\n",
    "    rf_classifier_baseline, X_test, y_test, cv=5, scoring=\"f1_weighted\"\n",
    ")\n",
    "\n",
    "# Print out the cross-validation scores\n",
    "print(\"Baseline model cross-validation scores: \", cv_scores)\n",
    "print(\"Baseline model mean cross-validation score: \", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get random data to test predicting values function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmsp</th>\n",
       "      <th>country</th>\n",
       "      <th>amount</th>\n",
       "      <th>3D_secured</th>\n",
       "      <th>card</th>\n",
       "      <th>previous_attemps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>2019-01-05 14:06:04</td>\n",
       "      <td>Austria</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>Master</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22530</th>\n",
       "      <td>2019-01-27 04:44:57</td>\n",
       "      <td>Germany</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>Diners</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>2019-01-17 20:30:02</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>Master</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>2019-01-03 21:01:04</td>\n",
       "      <td>Germany</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>Master</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36168</th>\n",
       "      <td>2019-02-11 08:20:46</td>\n",
       "      <td>Austria</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>Master</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tmsp      country  amount  3D_secured    card  \\\n",
       "5087  2019-01-05 14:06:04      Austria     215           0  Master   \n",
       "22530 2019-01-27 04:44:57      Germany     240           0  Diners   \n",
       "15518 2019-01-17 20:30:02  Switzerland     382           1  Master   \n",
       "3418  2019-01-03 21:01:04      Germany      32           1  Master   \n",
       "36168 2019-02-11 08:20:46      Austria     211           0  Master   \n",
       "\n",
       "       previous_attemps  \n",
       "5087                  1  \n",
       "22530                 1  \n",
       "15518                 3  \n",
       "3418                  1  \n",
       "36168                 3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some original Data to test\n",
    "original_data = pd.read_excel(\"../data/raw/PSP_Jan_Feb_2019.xlsx\", index_col=0)\n",
    "testdata = original_data.sample(5, random_state=42)\n",
    "# Add previous_attemps & delete PSP\n",
    "testdata[\"previous_attemps\"] = np.random.randint(low=0, high=4, size=(len(testdata),))\n",
    "testdata.drop(\"PSP\", axis=1, inplace=True)\n",
    "testdata.drop(\"success\", axis=1, inplace=True)\n",
    "testdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build function to predict PSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(input_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param input_df: DataFrame with values for \"tmsp\", \"country\", \"amount\", \"success\", \"3D_secured\", \"previous_attemps\" and \"card\"\n",
    "    \"\"\"\n",
    "    input_df[\"Day of Month\"] = input_df[\"tmsp\"].dt.day  # Extract day from timestamp\n",
    "    input_df[\"Day of Week\"] = input_df[\n",
    "        \"tmsp\"\n",
    "    ].dt.dayofweek  # Extract day of the week from timestamp\n",
    "    input_df[\"Time of Day\"] = input_df[\"tmsp\"].dt.hour  # Extract hour from timestamp\n",
    "    input_df.drop(\"tmsp\", axis=1, inplace=True)\n",
    "    input_df.drop(\"country\", axis=1, inplace=True)\n",
    "\n",
    "    # One-Hot-Encode Card\n",
    "    list_card = [\"Diners\", \"Master\", \"Visa\"]\n",
    "    for card in list_card:\n",
    "        input_df[\"CARD_\" + card] = 0\n",
    "    for index, row in input_df.iterrows():\n",
    "        input_df.loc[index, \"CARD_\" + row[\"card\"]] = 1\n",
    "    input_df.drop(\"card\", axis=1, inplace=True)\n",
    "    input_df = input_df.sort_index(axis=1)\n",
    "    return input_df\n",
    "\n",
    "\n",
    "def find_best_psp(x: pd.Series, possible_psps: pd.DataFrame):\n",
    "    series = x.copy()\n",
    "    series.index = series.index.str[15:]\n",
    "    df = series.to_frame(name=\"success_probability\")\n",
    "    df[\"cost\"] = df.apply(lambda x: possible_psps.loc[x.name, \"Cost_success\"], axis=1)\n",
    "    weight_on_success = 0.75\n",
    "    weight_on_costs = 0.25\n",
    "    df[\"weighted_score\"] = df.apply(\n",
    "        lambda x: weight_on_success * x[\"success_probability\"]\n",
    "        + weight_on_costs * (1 / x[\"cost\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    # print(f\"Following Dataframe should take {df[\"weighted_score\"].idxmax()} as the PSP\")\n",
    "    # print(df.head())\n",
    "    return df[\"weighted_score\"].idxmax()\n",
    "\n",
    "\n",
    "def predict_psp_baseline(input_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    :param input_df: DataFrame with values for \"tmsp\", \"country\", \"amount\", \"success\", \"3D_secured\", \"previous_attemps\" and \"card\"\n",
    "    \"\"\"\n",
    "    # Feature engineering\n",
    "    input_df = transform_data(input_df)\n",
    "\n",
    "    # Possible PSP with costs\n",
    "    possible_psps = pd.DataFrame(\n",
    "        {\n",
    "            \"PSP\": [\"Goldcard\", \"Moneycard\", \"Simplecard\", \"UK_Card\"],\n",
    "            \"Cost_success\": [10, 5, 1.0, 3],\n",
    "            \"Cost_failure\": [5, 2, 0.5, 1],\n",
    "        }\n",
    "    ).set_index(\"PSP\")\n",
    "    # Init PSP prediction columns\n",
    "    prediction_column = \"PSP_PREDICTION_\"\n",
    "    psp_prediction_columns = []\n",
    "    for psp in possible_psps.index:\n",
    "        input_df[\"PSP_\" + psp] = 0\n",
    "        psp_prediction_columns.append(\"PSP_PREDICTION_\" + psp)\n",
    "    input_df = input_df.sort_index(axis=1)\n",
    "    input_with_prediction = input_df.copy()\n",
    "\n",
    "    # Find PSP with highest\n",
    "    for index, psp in possible_psps.iterrows():\n",
    "        # Test out using this PSP\n",
    "        datapoints_copy = input_df.copy()\n",
    "        datapoints_copy[\"PSP_\" + index] = 1\n",
    "        input_with_prediction[prediction_column + index] = (\n",
    "            rf_classifier_baseline.predict_proba(datapoints_copy)[:, 1]\n",
    "        )\n",
    "\n",
    "    # Find max probability\n",
    "\n",
    "    input_with_prediction[\"Best PSP\"] = input_with_prediction[\n",
    "        psp_prediction_columns\n",
    "    ].idxmax(axis=1)\n",
    "    input_with_prediction[\"Best Probability\"] = input_with_prediction.apply(\n",
    "        lambda x: x[x[\"Best PSP\"]], axis=1\n",
    "    )\n",
    "    input_with_prediction[\"Best PSP\"] = input_with_prediction[\"Best PSP\"].str[15:]\n",
    "    # print(input_with_prediction.head())\n",
    "    # Taking costs into account\n",
    "    input_with_prediction[\"Recommendation\"] = input_with_prediction[\n",
    "        psp_prediction_columns\n",
    "    ].apply(lambda x: find_best_psp(x, possible_psps), axis=1)\n",
    "    input_with_prediction.drop(psp_prediction_columns, axis=1, inplace=True)\n",
    "\n",
    "    return input_with_prediction[[\"Best PSP\", \"Best Probability\", \"Recommendation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best PSP</th>\n",
       "      <th>Best Probability</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15518</th>\n",
       "      <td>Goldcard</td>\n",
       "      <td>0.541183</td>\n",
       "      <td>Goldcard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22530</th>\n",
       "      <td>Goldcard</td>\n",
       "      <td>0.265807</td>\n",
       "      <td>Simplecard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>Moneycard</td>\n",
       "      <td>0.317841</td>\n",
       "      <td>Simplecard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36168</th>\n",
       "      <td>Goldcard</td>\n",
       "      <td>0.405290</td>\n",
       "      <td>Goldcard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>Goldcard</td>\n",
       "      <td>0.367369</td>\n",
       "      <td>Simplecard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Best PSP  Best Probability Recommendation\n",
       "15518   Goldcard          0.541183       Goldcard\n",
       "22530   Goldcard          0.265807     Simplecard\n",
       "3418   Moneycard          0.317841     Simplecard\n",
       "36168   Goldcard          0.405290       Goldcard\n",
       "5087    Goldcard          0.367369     Simplecard"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_psp_baseline(testdata.sample(5)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Initialisierung und Training des Random Forest Classifiers\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [30, 100, 300, 1000],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 10, None],\n",
    "    \"max_depth\": [3, 6, 8, 10],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_weighted\",\n",
    ")\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n",
      "Test F1-Score:  0.746898415360445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimator\n",
    "best_random_forest = RandomForestClassifier(\n",
    "    verbose=3, random_state=42, n_estimators=100, max_depth=10, max_features=None\n",
    ")\n",
    "best_random_forest.fit(X_train, y_train)\n",
    "# Predict the target on the test data\n",
    "predictions = best_random_forest.predict(X_test)\n",
    "# Print Precision\n",
    "print(\"Test F1-Score: \", f1_score(y_test, predictions, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9902           29.48s\n",
      "         2           0.9765           28.21s\n",
      "         3           0.9654           28.82s\n",
      "         4           0.9564           28.40s\n",
      "         5           0.9489           28.55s\n",
      "         6           0.9425           28.18s\n",
      "         7           0.9372           27.93s\n",
      "         8           0.9325           28.02s\n",
      "         9           0.9286           28.10s\n",
      "        10           0.9251           28.16s\n",
      "        11           0.9219           28.03s\n",
      "        12           0.9192           28.02s\n",
      "        13           0.9165           27.88s\n",
      "        14           0.9139           27.78s\n",
      "        15           0.9116           27.60s\n",
      "        16           0.9096           27.57s\n",
      "        17           0.9075           27.55s\n",
      "        18           0.9052           27.46s\n",
      "        19           0.9035           27.31s\n",
      "        20           0.9012           27.28s\n",
      "        21           0.8998           27.31s\n",
      "        22           0.8979           27.24s\n",
      "        23           0.8961           27.10s\n",
      "        24           0.8944           27.06s\n",
      "        25           0.8924           26.99s\n",
      "        26           0.8907           26.94s\n",
      "        27           0.8880           27.00s\n",
      "        28           0.8861           26.98s\n",
      "        29           0.8838           26.91s\n",
      "        30           0.8822           26.77s\n",
      "        31           0.8802           26.69s\n",
      "        32           0.8781           26.63s\n",
      "        33           0.8771           26.57s\n",
      "        34           0.8753           26.46s\n",
      "        35           0.8738           26.40s\n",
      "        36           0.8719           26.30s\n",
      "        37           0.8707           26.23s\n",
      "        38           0.8694           26.17s\n",
      "        39           0.8683           26.13s\n",
      "        40           0.8666           26.05s\n",
      "        41           0.8659           25.99s\n",
      "        42           0.8638           25.91s\n",
      "        43           0.8623           25.85s\n",
      "        44           0.8607           25.78s\n",
      "        45           0.8593           25.85s\n",
      "        46           0.8587           25.77s\n",
      "        47           0.8572           25.72s\n",
      "        48           0.8562           25.65s\n",
      "        49           0.8540           25.58s\n",
      "        50           0.8525           25.53s\n",
      "        51           0.8514           25.44s\n",
      "        52           0.8499           25.36s\n",
      "        53           0.8488           25.32s\n",
      "        54           0.8482           25.24s\n",
      "        55           0.8475           25.15s\n",
      "        56           0.8460           25.08s\n",
      "        57           0.8442           25.05s\n",
      "        58           0.8431           24.97s\n",
      "        59           0.8418           24.91s\n",
      "        60           0.8414           24.84s\n",
      "        61           0.8406           24.78s\n",
      "        62           0.8394           24.72s\n",
      "        63           0.8384           24.71s\n",
      "        64           0.8373           24.68s\n",
      "        65           0.8362           24.61s\n",
      "        66           0.8349           24.53s\n",
      "        67           0.8340           24.47s\n",
      "        68           0.8332           24.40s\n",
      "        69           0.8321           24.34s\n",
      "        70           0.8312           24.28s\n",
      "        71           0.8303           24.21s\n",
      "        72           0.8286           24.15s\n",
      "        73           0.8277           24.12s\n",
      "        74           0.8260           24.07s\n",
      "        75           0.8257           24.00s\n",
      "        76           0.8239           23.95s\n",
      "        77           0.8223           23.91s\n",
      "        78           0.8205           23.89s\n",
      "        79           0.8192           23.82s\n",
      "        80           0.8180           23.84s\n",
      "        81           0.8170           23.77s\n",
      "        82           0.8153           23.71s\n",
      "        83           0.8150           23.63s\n",
      "        84           0.8139           23.57s\n",
      "        85           0.8125           23.53s\n",
      "        86           0.8111           23.46s\n",
      "        87           0.8096           23.40s\n",
      "        88           0.8085           23.35s\n",
      "        89           0.8083           23.29s\n",
      "        90           0.8072           23.22s\n",
      "        91           0.8066           23.16s\n",
      "        92           0.8057           23.09s\n",
      "        93           0.8053           23.03s\n",
      "        94           0.8048           22.96s\n",
      "        95           0.8035           22.89s\n",
      "        96           0.8024           22.83s\n",
      "        97           0.8009           22.78s\n",
      "        98           0.7990           22.77s\n",
      "        99           0.7973           22.71s\n",
      "       100           0.7957           22.65s\n",
      "       101           0.7949           22.59s\n",
      "       102           0.7933           22.52s\n",
      "       103           0.7924           22.46s\n",
      "       104           0.7910           22.39s\n",
      "       105           0.7901           22.34s\n",
      "       106           0.7891           22.28s\n",
      "       107           0.7889           22.21s\n",
      "       108           0.7882           22.15s\n",
      "       109           0.7874           22.10s\n",
      "       110           0.7872           22.05s\n",
      "       111           0.7865           21.98s\n",
      "       112           0.7852           21.94s\n",
      "       113           0.7834           21.88s\n",
      "       114           0.7818           21.82s\n",
      "       115           0.7811           21.78s\n",
      "       116           0.7811           21.75s\n",
      "       117           0.7795           21.69s\n",
      "       118           0.7791           21.63s\n",
      "       119           0.7775           21.57s\n",
      "       120           0.7762           21.51s\n",
      "       121           0.7745           21.45s\n",
      "       122           0.7738           21.39s\n",
      "       123           0.7724           21.32s\n",
      "       124           0.7714           21.26s\n",
      "       125           0.7709           21.21s\n",
      "       126           0.7704           21.15s\n",
      "       127           0.7691           21.09s\n",
      "       128           0.7681           21.04s\n",
      "       129           0.7666           20.99s\n",
      "       130           0.7661           20.93s\n",
      "       131           0.7645           20.87s\n",
      "       132           0.7628           20.80s\n",
      "       133           0.7615           20.78s\n",
      "       134           0.7609           20.75s\n",
      "       135           0.7594           20.69s\n",
      "       136           0.7586           20.64s\n",
      "       137           0.7576           20.58s\n",
      "       138           0.7567           20.52s\n",
      "       139           0.7562           20.45s\n",
      "       140           0.7545           20.39s\n",
      "       141           0.7533           20.34s\n",
      "       142           0.7519           20.28s\n",
      "       143           0.7504           20.22s\n",
      "       144           0.7492           20.17s\n",
      "       145           0.7487           20.12s\n",
      "       146           0.7473           20.05s\n",
      "       147           0.7467           19.99s\n",
      "       148           0.7457           19.93s\n",
      "       149           0.7445           19.88s\n",
      "       150           0.7439           19.82s\n",
      "       151           0.7428           19.80s\n",
      "       152           0.7424           19.75s\n",
      "       153           0.7422           19.68s\n",
      "       154           0.7411           19.62s\n",
      "       155           0.7411           19.55s\n",
      "       156           0.7399           19.49s\n",
      "       157           0.7389           19.44s\n",
      "       158           0.7380           19.38s\n",
      "       159           0.7368           19.33s\n",
      "       160           0.7354           19.29s\n",
      "       161           0.7339           19.31s\n",
      "       162           0.7330           19.29s\n",
      "       163           0.7318           19.29s\n",
      "       164           0.7304           19.30s\n",
      "       165           0.7297           19.30s\n",
      "       166           0.7286           19.29s\n",
      "       167           0.7277           19.28s\n",
      "       168           0.7265           19.25s\n",
      "       169           0.7254           19.21s\n",
      "       170           0.7242           19.19s\n",
      "       171           0.7238           19.15s\n",
      "       172           0.7226           19.10s\n",
      "       173           0.7224           19.03s\n",
      "       174           0.7212           18.98s\n",
      "       175           0.7201           18.92s\n",
      "       176           0.7188           18.86s\n",
      "       177           0.7177           18.80s\n",
      "       178           0.7165           18.77s\n",
      "       179           0.7154           18.72s\n",
      "       180           0.7144           18.66s\n",
      "       181           0.7130           18.62s\n",
      "       182           0.7117           18.56s\n",
      "       183           0.7104           18.50s\n",
      "       184           0.7095           18.44s\n",
      "       185           0.7085           18.37s\n",
      "       186           0.7076           18.31s\n",
      "       187           0.7065           18.25s\n",
      "       188           0.7054           18.18s\n",
      "       189           0.7046           18.12s\n",
      "       190           0.7037           18.06s\n",
      "       191           0.7027           18.00s\n",
      "       192           0.7015           17.94s\n",
      "       193           0.7006           17.88s\n",
      "       194           0.6994           17.82s\n",
      "       195           0.6982           17.76s\n",
      "       196           0.6972           17.70s\n",
      "       197           0.6961           17.63s\n",
      "       198           0.6952           17.58s\n",
      "       199           0.6942           17.53s\n",
      "       200           0.6928           17.47s\n",
      "       201           0.6922           17.40s\n",
      "       202           0.6914           17.34s\n",
      "       203           0.6905           17.28s\n",
      "       204           0.6898           17.21s\n",
      "       205           0.6887           17.15s\n",
      "       206           0.6879           17.09s\n",
      "       207           0.6871           17.03s\n",
      "       208           0.6859           16.97s\n",
      "       209           0.6852           16.91s\n",
      "       210           0.6845           16.85s\n",
      "       211           0.6839           16.79s\n",
      "       212           0.6828           16.72s\n",
      "       213           0.6822           16.66s\n",
      "       214           0.6814           16.60s\n",
      "       215           0.6806           16.54s\n",
      "       216           0.6800           16.49s\n",
      "       217           0.6790           16.43s\n",
      "       218           0.6781           16.37s\n",
      "       219           0.6773           16.32s\n",
      "       220           0.6771           16.25s\n",
      "       221           0.6763           16.19s\n",
      "       222           0.6759           16.12s\n",
      "       223           0.6749           16.06s\n",
      "       224           0.6741           16.00s\n",
      "       225           0.6727           15.94s\n",
      "       226           0.6718           15.88s\n",
      "       227           0.6709           15.82s\n",
      "       228           0.6706           15.76s\n",
      "       229           0.6697           15.70s\n",
      "       230           0.6688           15.64s\n",
      "       231           0.6678           15.58s\n",
      "       232           0.6669           15.52s\n",
      "       233           0.6666           15.46s\n",
      "       234           0.6660           15.42s\n",
      "       235           0.6658           15.36s\n",
      "       236           0.6648           15.30s\n",
      "       237           0.6646           15.24s\n",
      "       238           0.6638           15.18s\n",
      "       239           0.6635           15.12s\n",
      "       240           0.6625           15.06s\n",
      "       241           0.6619           14.99s\n",
      "       242           0.6614           14.93s\n",
      "       243           0.6610           14.87s\n",
      "       244           0.6603           14.81s\n",
      "       245           0.6601           14.75s\n",
      "       246           0.6595           14.69s\n",
      "       247           0.6586           14.63s\n",
      "       248           0.6581           14.57s\n",
      "       249           0.6575           14.51s\n",
      "       250           0.6568           14.45s\n",
      "       251           0.6563           14.40s\n",
      "       252           0.6559           14.34s\n",
      "       253           0.6552           14.28s\n",
      "       254           0.6550           14.22s\n",
      "       255           0.6540           14.16s\n",
      "       256           0.6535           14.10s\n",
      "       257           0.6530           14.04s\n",
      "       258           0.6526           13.98s\n",
      "       259           0.6517           13.92s\n",
      "       260           0.6507           13.86s\n",
      "       261           0.6504           13.79s\n",
      "       262           0.6497           13.74s\n",
      "       263           0.6493           13.68s\n",
      "       264           0.6484           13.62s\n",
      "       265           0.6474           13.56s\n",
      "       266           0.6467           13.50s\n",
      "       267           0.6463           13.44s\n",
      "       268           0.6457           13.38s\n",
      "       269           0.6449           13.32s\n",
      "       270           0.6439           13.27s\n",
      "       271           0.6432           13.21s\n",
      "       272           0.6429           13.15s\n",
      "       273           0.6421           13.09s\n",
      "       274           0.6418           13.03s\n",
      "       275           0.6409           12.97s\n",
      "       276           0.6398           12.91s\n",
      "       277           0.6387           12.85s\n",
      "       278           0.6380           12.80s\n",
      "       279           0.6369           12.74s\n",
      "       280           0.6358           12.68s\n",
      "       281           0.6351           12.62s\n",
      "       282           0.6345           12.56s\n",
      "       283           0.6336           12.51s\n",
      "       284           0.6330           12.47s\n",
      "       285           0.6325           12.41s\n",
      "       286           0.6321           12.36s\n",
      "       287           0.6310           12.31s\n",
      "       288           0.6303           12.25s\n",
      "       289           0.6293           12.19s\n",
      "       290           0.6282           12.13s\n",
      "       291           0.6277           12.07s\n",
      "       292           0.6267           12.01s\n",
      "       293           0.6258           11.95s\n",
      "       294           0.6253           11.89s\n",
      "       295           0.6248           11.83s\n",
      "       296           0.6242           11.78s\n",
      "       297           0.6239           11.72s\n",
      "       298           0.6234           11.66s\n",
      "       299           0.6230           11.60s\n",
      "       300           0.6218           11.54s\n",
      "       301           0.6214           11.48s\n",
      "       302           0.6207           11.42s\n",
      "       303           0.6203           11.36s\n",
      "       304           0.6196           11.31s\n",
      "       305           0.6194           11.25s\n",
      "       306           0.6186           11.20s\n",
      "       307           0.6179           11.14s\n",
      "       308           0.6171           11.08s\n",
      "       309           0.6160           11.03s\n",
      "       310           0.6149           10.97s\n",
      "       311           0.6147           10.91s\n",
      "       312           0.6138           10.85s\n",
      "       313           0.6127           10.79s\n",
      "       314           0.6124           10.73s\n",
      "       315           0.6120           10.67s\n",
      "       316           0.6118           10.62s\n",
      "       317           0.6114           10.56s\n",
      "       318           0.6107           10.50s\n",
      "       319           0.6099           10.44s\n",
      "       320           0.6090           10.39s\n",
      "       321           0.6085           10.34s\n",
      "       322           0.6085           10.29s\n",
      "       323           0.6076           10.23s\n",
      "       324           0.6066           10.17s\n",
      "       325           0.6058           10.11s\n",
      "       326           0.6047           10.05s\n",
      "       327           0.6038            9.99s\n",
      "       328           0.6030            9.93s\n",
      "       329           0.6025            9.87s\n",
      "       330           0.6018            9.82s\n",
      "       331           0.6015            9.76s\n",
      "       332           0.6005            9.70s\n",
      "       333           0.5997            9.64s\n",
      "       334           0.5990            9.58s\n",
      "       335           0.5981            9.52s\n",
      "       336           0.5971            9.47s\n",
      "       337           0.5963            9.42s\n",
      "       338           0.5956            9.37s\n",
      "       339           0.5947            9.31s\n",
      "       340           0.5941            9.25s\n",
      "       341           0.5932            9.19s\n",
      "       342           0.5923            9.13s\n",
      "       343           0.5916            9.07s\n",
      "       344           0.5907            9.01s\n",
      "       345           0.5899            8.96s\n",
      "       346           0.5890            8.90s\n",
      "       347           0.5882            8.84s\n",
      "       348           0.5875            8.78s\n",
      "       349           0.5865            8.72s\n",
      "       350           0.5856            8.67s\n",
      "       351           0.5847            8.61s\n",
      "       352           0.5838            8.55s\n",
      "       353           0.5831            8.49s\n",
      "       354           0.5824            8.43s\n",
      "       355           0.5816            8.38s\n",
      "       356           0.5809            8.33s\n",
      "       357           0.5804            8.27s\n",
      "       358           0.5797            8.21s\n",
      "       359           0.5790            8.15s\n",
      "       360           0.5784            8.10s\n",
      "       361           0.5779            8.04s\n",
      "       362           0.5772            7.98s\n",
      "       363           0.5764            7.93s\n",
      "       364           0.5757            7.87s\n",
      "       365           0.5749            7.81s\n",
      "       366           0.5743            7.75s\n",
      "       367           0.5738            7.69s\n",
      "       368           0.5731            7.64s\n",
      "       369           0.5725            7.58s\n",
      "       370           0.5719            7.52s\n",
      "       371           0.5711            7.46s\n",
      "       372           0.5705            7.40s\n",
      "       373           0.5699            7.35s\n",
      "       374           0.5691            7.29s\n",
      "       375           0.5685            7.23s\n",
      "       376           0.5680            7.17s\n",
      "       377           0.5673            7.11s\n",
      "       378           0.5667            7.06s\n",
      "       379           0.5661            7.00s\n",
      "       380           0.5660            6.94s\n",
      "       381           0.5655            6.88s\n",
      "       382           0.5650            6.82s\n",
      "       383           0.5645            6.76s\n",
      "       384           0.5641            6.70s\n",
      "       385           0.5636            6.65s\n",
      "       386           0.5629            6.59s\n",
      "       387           0.5624            6.53s\n",
      "       388           0.5619            6.47s\n",
      "       389           0.5609            6.41s\n",
      "       390           0.5603            6.36s\n",
      "       391           0.5594            6.30s\n",
      "       392           0.5588            6.24s\n",
      "       393           0.5581            6.18s\n",
      "       394           0.5576            6.13s\n",
      "       395           0.5569            6.07s\n",
      "       396           0.5563            6.01s\n",
      "       397           0.5554            5.95s\n",
      "       398           0.5549            5.89s\n",
      "       399           0.5541            5.84s\n",
      "       400           0.5535            5.78s\n",
      "       401           0.5529            5.72s\n",
      "       402           0.5523            5.66s\n",
      "       403           0.5515            5.61s\n",
      "       404           0.5507            5.55s\n",
      "       405           0.5499            5.49s\n",
      "       406           0.5494            5.43s\n",
      "       407           0.5488            5.37s\n",
      "       408           0.5481            5.32s\n",
      "       409           0.5472            5.26s\n",
      "       410           0.5466            5.20s\n",
      "       411           0.5462            5.14s\n",
      "       412           0.5457            5.08s\n",
      "       413           0.5453            5.03s\n",
      "       414           0.5445            4.97s\n",
      "       415           0.5438            4.91s\n",
      "       416           0.5432            4.85s\n",
      "       417           0.5426            4.80s\n",
      "       418           0.5421            4.74s\n",
      "       419           0.5414            4.68s\n",
      "       420           0.5407            4.62s\n",
      "       421           0.5406            4.57s\n",
      "       422           0.5406            4.51s\n",
      "       423           0.5399            4.45s\n",
      "       424           0.5392            4.39s\n",
      "       425           0.5389            4.34s\n",
      "       426           0.5384            4.29s\n",
      "       427           0.5380            4.23s\n",
      "       428           0.5377            4.17s\n",
      "       429           0.5372            4.11s\n",
      "       430           0.5368            4.05s\n",
      "       431           0.5360            4.00s\n",
      "       432           0.5357            3.94s\n",
      "       433           0.5356            3.88s\n",
      "       434           0.5348            3.82s\n",
      "       435           0.5341            3.77s\n",
      "       436           0.5334            3.71s\n",
      "       437           0.5327            3.65s\n",
      "       438           0.5319            3.59s\n",
      "       439           0.5314            3.53s\n",
      "       440           0.5306            3.47s\n",
      "       441           0.5303            3.42s\n",
      "       442           0.5297            3.36s\n",
      "       443           0.5292            3.30s\n",
      "       444           0.5288            3.24s\n",
      "       445           0.5282            3.19s\n",
      "       446           0.5276            3.13s\n",
      "       447           0.5272            3.07s\n",
      "       448           0.5266            3.01s\n",
      "       449           0.5261            2.95s\n",
      "       450           0.5253            2.89s\n",
      "       451           0.5247            2.84s\n",
      "       452           0.5239            2.78s\n",
      "       453           0.5234            2.72s\n",
      "       454           0.5228            2.66s\n",
      "       455           0.5220            2.60s\n",
      "       456           0.5213            2.55s\n",
      "       457           0.5205            2.49s\n",
      "       458           0.5202            2.43s\n",
      "       459           0.5193            2.37s\n",
      "       460           0.5187            2.31s\n",
      "       461           0.5180            2.26s\n",
      "       462           0.5176            2.20s\n",
      "       463           0.5168            2.14s\n",
      "       464           0.5164            2.08s\n",
      "       465           0.5157            2.02s\n",
      "       466           0.5152            1.97s\n",
      "       467           0.5147            1.91s\n",
      "       468           0.5142            1.85s\n",
      "       469           0.5135            1.79s\n",
      "       470           0.5130            1.73s\n",
      "       471           0.5122            1.68s\n",
      "       472           0.5119            1.62s\n",
      "       473           0.5114            1.56s\n",
      "       474           0.5110            1.50s\n",
      "       475           0.5104            1.44s\n",
      "       476           0.5098            1.39s\n",
      "       477           0.5093            1.33s\n",
      "       478           0.5088            1.27s\n",
      "       479           0.5081            1.21s\n",
      "       480           0.5076            1.16s\n",
      "       481           0.5070            1.10s\n",
      "       482           0.5066            1.04s\n",
      "       483           0.5057            0.98s\n",
      "       484           0.5052            0.92s\n",
      "       485           0.5048            0.87s\n",
      "       486           0.5041            0.81s\n",
      "       487           0.5033            0.75s\n",
      "       488           0.5025            0.69s\n",
      "       489           0.5019            0.64s\n",
      "       490           0.5018            0.58s\n",
      "       491           0.5011            0.52s\n",
      "       492           0.5007            0.46s\n",
      "       493           0.5002            0.40s\n",
      "       494           0.4998            0.35s\n",
      "       495           0.4993            0.29s\n",
      "       496           0.4988            0.23s\n",
      "       497           0.4983            0.17s\n",
      "       498           0.4977            0.12s\n",
      "       499           0.4973            0.06s\n",
      "       500           0.4968            0.00s\n",
      "{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialisierung und Training des Neural Net\n",
    "gboosting = GradientBoostingClassifier(verbose=3, random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 300, 500, 1000],\n",
    "    \"learning_rate\": [0.01, 0.1, 1],\n",
    "    \"max_depth\": [3, 7, 10],\n",
    "}\n",
    "\n",
    "\n",
    "CV_rfc = GridSearchCV(\n",
    "    estimator=gboosting,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_weighted\",\n",
    ")\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9902           46.41s\n",
      "         2           0.9765           40.43s\n",
      "         3           0.9654           37.37s\n",
      "         4           0.9564           36.28s\n",
      "         5           0.9489           34.97s\n",
      "         6           0.9425           33.56s\n",
      "         7           0.9372           33.04s\n",
      "         8           0.9325           32.68s\n",
      "         9           0.9286           32.67s\n",
      "        10           0.9251           33.08s\n",
      "        11           0.9219           32.90s\n",
      "        12           0.9192           32.51s\n",
      "        13           0.9165           32.08s\n",
      "        14           0.9139           32.98s\n",
      "        15           0.9116           34.10s\n",
      "        16           0.9096           35.09s\n",
      "        17           0.9075           35.85s\n",
      "        18           0.9052           36.20s\n",
      "        19           0.9035           36.13s\n",
      "        20           0.9012           35.74s\n",
      "        21           0.8998           35.63s\n",
      "        22           0.8979           35.64s\n",
      "        23           0.8961           35.47s\n",
      "        24           0.8944           35.21s\n",
      "        25           0.8924           34.95s\n",
      "        26           0.8907           34.59s\n",
      "        27           0.8880           34.33s\n",
      "        28           0.8861           34.13s\n",
      "        29           0.8838           33.87s\n",
      "        30           0.8822           33.90s\n",
      "        31           0.8802           33.71s\n",
      "        32           0.8781           33.52s\n",
      "        33           0.8771           33.29s\n",
      "        34           0.8753           33.03s\n",
      "        35           0.8738           32.86s\n",
      "        36           0.8719           32.72s\n",
      "        37           0.8707           32.59s\n",
      "        38           0.8694           32.36s\n",
      "        39           0.8683           32.17s\n",
      "        40           0.8666           31.97s\n",
      "        41           0.8659           31.72s\n",
      "        42           0.8638           31.51s\n",
      "        43           0.8623           31.34s\n",
      "        44           0.8607           31.16s\n",
      "        45           0.8593           30.96s\n",
      "        46           0.8587           30.86s\n",
      "        47           0.8572           30.74s\n",
      "        48           0.8562           30.55s\n",
      "        49           0.8540           30.38s\n",
      "        50           0.8525           30.24s\n",
      "        51           0.8514           30.09s\n",
      "        52           0.8499           29.92s\n",
      "        53           0.8488           29.74s\n",
      "        54           0.8482           29.56s\n",
      "        55           0.8475           29.41s\n",
      "        56           0.8460           29.27s\n",
      "        57           0.8442           29.10s\n",
      "        58           0.8431           29.00s\n",
      "        59           0.8418           28.84s\n",
      "        60           0.8414           28.70s\n",
      "        61           0.8406           28.55s\n",
      "        62           0.8394           28.42s\n",
      "        63           0.8384           28.33s\n",
      "        64           0.8373           28.29s\n",
      "        65           0.8362           28.17s\n",
      "        66           0.8349           28.06s\n",
      "        67           0.8340           27.95s\n",
      "        68           0.8332           27.81s\n",
      "        69           0.8321           27.68s\n",
      "        70           0.8312           27.55s\n",
      "        71           0.8303           27.43s\n",
      "        72           0.8286           27.32s\n",
      "        73           0.8277           27.21s\n",
      "        74           0.8260           27.12s\n",
      "        75           0.8257           27.01s\n",
      "        76           0.8239           26.90s\n",
      "        77           0.8223           26.78s\n",
      "        78           0.8205           26.67s\n",
      "        79           0.8192           26.58s\n",
      "        80           0.8180           26.49s\n",
      "        81           0.8170           26.42s\n",
      "        82           0.8153           26.34s\n",
      "        83           0.8150           26.23s\n",
      "        84           0.8139           26.14s\n",
      "        85           0.8125           26.04s\n",
      "        86           0.8111           25.94s\n",
      "        87           0.8096           25.84s\n",
      "        88           0.8085           25.76s\n",
      "        89           0.8083           25.66s\n",
      "        90           0.8072           25.58s\n",
      "        91           0.8066           25.48s\n",
      "        92           0.8057           25.40s\n",
      "        93           0.8053           25.29s\n",
      "        94           0.8048           25.20s\n",
      "        95           0.8035           25.11s\n",
      "        96           0.8024           25.02s\n",
      "        97           0.8009           24.94s\n",
      "        98           0.7990           24.85s\n",
      "        99           0.7973           24.84s\n",
      "       100           0.7957           24.77s\n",
      "       101           0.7949           24.67s\n",
      "       102           0.7933           24.59s\n",
      "       103           0.7924           24.49s\n",
      "       104           0.7910           24.42s\n",
      "       105           0.7901           24.33s\n",
      "       106           0.7891           24.24s\n",
      "       107           0.7889           24.15s\n",
      "       108           0.7882           24.07s\n",
      "       109           0.7874           23.99s\n",
      "       110           0.7872           23.89s\n",
      "       111           0.7865           23.80s\n",
      "       112           0.7852           23.73s\n",
      "       113           0.7834           23.65s\n",
      "       114           0.7818           23.56s\n",
      "       115           0.7811           23.48s\n",
      "       116           0.7811           23.40s\n",
      "       117           0.7795           23.34s\n",
      "       118           0.7791           23.27s\n",
      "       119           0.7775           23.19s\n",
      "       120           0.7762           23.12s\n",
      "       121           0.7745           23.03s\n",
      "       122           0.7738           22.95s\n",
      "       123           0.7724           22.87s\n",
      "       124           0.7714           22.80s\n",
      "       125           0.7709           22.72s\n",
      "       126           0.7704           22.64s\n",
      "       127           0.7691           22.58s\n",
      "       128           0.7681           22.50s\n",
      "       129           0.7666           22.42s\n",
      "       130           0.7661           22.34s\n",
      "       131           0.7645           22.26s\n",
      "       132           0.7628           22.18s\n",
      "       133           0.7615           22.11s\n",
      "       134           0.7609           22.03s\n",
      "       135           0.7594           22.00s\n",
      "       136           0.7586           21.93s\n",
      "       137           0.7576           21.86s\n",
      "       138           0.7567           21.78s\n",
      "       139           0.7562           21.70s\n",
      "       140           0.7545           21.63s\n",
      "       141           0.7533           21.56s\n",
      "       142           0.7519           21.48s\n",
      "       143           0.7504           21.41s\n",
      "       144           0.7492           21.35s\n",
      "       145           0.7487           21.28s\n",
      "       146           0.7473           21.20s\n",
      "       147           0.7467           21.13s\n",
      "       148           0.7457           21.06s\n",
      "       149           0.7445           21.00s\n",
      "       150           0.7439           20.92s\n",
      "       151           0.7428           20.85s\n",
      "       152           0.7424           20.78s\n",
      "       153           0.7422           20.73s\n",
      "       154           0.7411           20.66s\n",
      "       155           0.7411           20.58s\n",
      "       156           0.7399           20.52s\n",
      "       157           0.7389           20.44s\n",
      "       158           0.7380           20.37s\n",
      "       159           0.7368           20.31s\n",
      "       160           0.7354           20.27s\n",
      "       161           0.7339           20.20s\n",
      "       162           0.7330           20.14s\n",
      "       163           0.7318           20.08s\n",
      "       164           0.7304           20.01s\n",
      "       165           0.7297           19.94s\n",
      "       166           0.7286           19.88s\n",
      "       167           0.7277           19.82s\n",
      "       168           0.7265           19.76s\n",
      "       169           0.7254           19.69s\n",
      "       170           0.7242           19.64s\n",
      "       171           0.7238           19.58s\n",
      "       172           0.7226           19.52s\n",
      "       173           0.7224           19.44s\n",
      "       174           0.7212           19.38s\n",
      "       175           0.7201           19.32s\n",
      "       176           0.7188           19.26s\n",
      "       177           0.7177           19.19s\n",
      "       178           0.7165           19.13s\n",
      "       179           0.7154           19.06s\n",
      "       180           0.7144           19.00s\n",
      "       181           0.7130           18.93s\n",
      "       182           0.7117           18.86s\n",
      "       183           0.7104           18.79s\n",
      "       184           0.7095           18.78s\n",
      "       185           0.7085           18.71s\n",
      "       186           0.7076           18.64s\n",
      "       187           0.7065           18.61s\n",
      "       188           0.7054           18.56s\n",
      "       189           0.7046           18.50s\n",
      "       190           0.7037           18.43s\n",
      "       191           0.7027           18.37s\n",
      "       192           0.7015           18.31s\n",
      "       193           0.7006           18.24s\n",
      "       194           0.6994           18.18s\n",
      "       195           0.6982           18.12s\n",
      "       196           0.6972           18.06s\n",
      "       197           0.6961           17.99s\n",
      "       198           0.6952           17.93s\n",
      "       199           0.6942           17.86s\n",
      "       200           0.6928           17.80s\n",
      "       201           0.6922           17.73s\n",
      "       202           0.6914           17.66s\n",
      "       203           0.6905           17.60s\n",
      "       204           0.6898           17.54s\n",
      "       205           0.6887           17.50s\n",
      "       206           0.6879           17.43s\n",
      "       207           0.6871           17.37s\n",
      "       208           0.6859           17.31s\n",
      "       209           0.6852           17.24s\n",
      "       210           0.6845           17.18s\n",
      "       211           0.6839           17.12s\n",
      "       212           0.6828           17.06s\n",
      "       213           0.6822           17.00s\n",
      "       214           0.6814           16.94s\n",
      "       215           0.6806           16.87s\n",
      "       216           0.6800           16.81s\n",
      "       217           0.6790           16.74s\n",
      "       218           0.6781           16.68s\n",
      "       219           0.6773           16.61s\n",
      "       220           0.6771           16.55s\n",
      "       221           0.6763           16.49s\n",
      "       222           0.6759           16.42s\n",
      "       223           0.6749           16.38s\n",
      "       224           0.6741           16.32s\n",
      "       225           0.6727           16.25s\n",
      "       226           0.6718           16.19s\n",
      "       227           0.6709           16.12s\n",
      "       228           0.6706           16.06s\n",
      "       229           0.6697           16.01s\n",
      "       230           0.6688           15.94s\n",
      "       231           0.6678           15.88s\n",
      "       232           0.6669           15.82s\n",
      "       233           0.6666           15.76s\n",
      "       234           0.6660           15.70s\n",
      "       235           0.6658           15.63s\n",
      "       236           0.6648           15.58s\n",
      "       237           0.6646           15.51s\n",
      "       238           0.6638           15.45s\n",
      "       239           0.6635           15.39s\n",
      "       240           0.6625           15.34s\n",
      "       241           0.6619           15.28s\n",
      "       242           0.6614           15.22s\n",
      "       243           0.6610           15.15s\n",
      "       244           0.6603           15.09s\n",
      "       245           0.6601           15.03s\n",
      "       246           0.6595           14.96s\n",
      "       247           0.6586           14.90s\n",
      "       248           0.6581           14.84s\n",
      "       249           0.6575           14.78s\n",
      "       250           0.6568           14.72s\n",
      "       251           0.6563           14.65s\n",
      "       252           0.6559           14.59s\n",
      "       253           0.6552           14.53s\n",
      "       254           0.6550           14.47s\n",
      "       255           0.6540           14.41s\n",
      "       256           0.6535           14.34s\n",
      "       257           0.6530           14.28s\n",
      "       258           0.6526           14.23s\n",
      "       259           0.6517           14.17s\n",
      "       260           0.6507           14.11s\n",
      "       261           0.6504           14.05s\n",
      "       262           0.6497           13.99s\n",
      "       263           0.6493           13.93s\n",
      "       264           0.6484           13.86s\n",
      "       265           0.6474           13.80s\n",
      "       266           0.6467           13.74s\n",
      "       267           0.6463           13.68s\n",
      "       268           0.6457           13.62s\n",
      "       269           0.6449           13.56s\n",
      "       270           0.6439           13.49s\n",
      "       271           0.6432           13.43s\n",
      "       272           0.6429           13.37s\n",
      "       273           0.6421           13.31s\n",
      "       274           0.6418           13.25s\n",
      "       275           0.6409           13.20s\n",
      "       276           0.6398           13.14s\n",
      "       277           0.6387           13.08s\n",
      "       278           0.6380           13.02s\n",
      "       279           0.6369           12.96s\n",
      "       280           0.6358           12.90s\n",
      "       281           0.6351           12.84s\n",
      "       282           0.6345           12.77s\n",
      "       283           0.6336           12.71s\n",
      "       284           0.6330           12.66s\n",
      "       285           0.6325           12.59s\n",
      "       286           0.6321           12.53s\n",
      "       287           0.6310           12.47s\n",
      "       288           0.6303           12.41s\n",
      "       289           0.6293           12.35s\n",
      "       290           0.6282           12.29s\n",
      "       291           0.6277           12.23s\n",
      "       292           0.6267           12.17s\n",
      "       293           0.6258           12.12s\n",
      "       294           0.6253           12.06s\n",
      "       295           0.6248           12.00s\n",
      "       296           0.6242           11.94s\n",
      "       297           0.6239           11.88s\n",
      "       298           0.6234           11.82s\n",
      "       299           0.6230           11.76s\n",
      "       300           0.6218           11.70s\n",
      "       301           0.6214           11.64s\n",
      "       302           0.6207           11.57s\n",
      "       303           0.6203           11.51s\n",
      "       304           0.6196           11.45s\n",
      "       305           0.6194           11.39s\n",
      "       306           0.6186           11.33s\n",
      "       307           0.6179           11.27s\n",
      "       308           0.6171           11.21s\n",
      "       309           0.6160           11.15s\n",
      "       310           0.6149           11.09s\n",
      "       311           0.6147           11.04s\n",
      "       312           0.6138           10.98s\n",
      "       313           0.6127           10.92s\n",
      "       314           0.6124           10.86s\n",
      "       315           0.6120           10.80s\n",
      "       316           0.6118           10.74s\n",
      "       317           0.6114           10.68s\n",
      "       318           0.6107           10.62s\n",
      "       319           0.6099           10.55s\n",
      "       320           0.6090           10.50s\n",
      "       321           0.6085           10.43s\n",
      "       322           0.6085           10.37s\n",
      "       323           0.6076           10.31s\n",
      "       324           0.6066           10.26s\n",
      "       325           0.6058           10.20s\n",
      "       326           0.6047           10.14s\n",
      "       327           0.6038           10.08s\n",
      "       328           0.6030           10.03s\n",
      "       329           0.6025            9.97s\n",
      "       330           0.6018            9.91s\n",
      "       331           0.6015            9.86s\n",
      "       332           0.6005            9.80s\n",
      "       333           0.5997            9.74s\n",
      "       334           0.5990            9.68s\n",
      "       335           0.5981            9.62s\n",
      "       336           0.5971            9.56s\n",
      "       337           0.5963            9.50s\n",
      "       338           0.5956            9.44s\n",
      "       339           0.5947            9.38s\n",
      "       340           0.5941            9.32s\n",
      "       341           0.5932            9.26s\n",
      "       342           0.5923            9.20s\n",
      "       343           0.5916            9.14s\n",
      "       344           0.5907            9.09s\n",
      "       345           0.5899            9.03s\n",
      "       346           0.5890            8.97s\n",
      "       347           0.5882            8.92s\n",
      "       348           0.5875            8.86s\n",
      "       349           0.5865            8.80s\n",
      "       350           0.5856            8.74s\n",
      "       351           0.5847            8.69s\n",
      "       352           0.5838            8.63s\n",
      "       353           0.5831            8.57s\n",
      "       354           0.5824            8.51s\n",
      "       355           0.5816            8.46s\n",
      "       356           0.5809            8.40s\n",
      "       357           0.5804            8.34s\n",
      "       358           0.5797            8.28s\n",
      "       359           0.5790            8.23s\n",
      "       360           0.5784            8.18s\n",
      "       361           0.5779            8.13s\n",
      "       362           0.5772            8.08s\n",
      "       363           0.5764            8.02s\n",
      "       364           0.5757            7.96s\n",
      "       365           0.5749            7.90s\n",
      "       366           0.5743            7.84s\n",
      "       367           0.5738            7.79s\n",
      "       368           0.5731            7.73s\n",
      "       369           0.5725            7.67s\n",
      "       370           0.5719            7.62s\n",
      "       371           0.5711            7.57s\n",
      "       372           0.5705            7.52s\n",
      "       373           0.5699            7.46s\n",
      "       374           0.5691            7.40s\n",
      "       375           0.5685            7.34s\n",
      "       376           0.5680            7.28s\n",
      "       377           0.5673            7.23s\n",
      "       378           0.5667            7.17s\n",
      "       379           0.5661            7.11s\n",
      "       380           0.5660            7.05s\n",
      "       381           0.5655            6.99s\n",
      "       382           0.5650            6.94s\n",
      "       383           0.5645            6.89s\n",
      "       384           0.5641            6.83s\n",
      "       385           0.5636            6.77s\n",
      "       386           0.5629            6.71s\n",
      "       387           0.5624            6.65s\n",
      "       388           0.5619            6.59s\n",
      "       389           0.5609            6.53s\n",
      "       390           0.5603            6.47s\n",
      "       391           0.5594            6.41s\n",
      "       392           0.5588            6.35s\n",
      "       393           0.5581            6.29s\n",
      "       394           0.5576            6.24s\n",
      "       395           0.5569            6.18s\n",
      "       396           0.5563            6.12s\n",
      "       397           0.5554            6.06s\n",
      "       398           0.5549            6.00s\n",
      "       399           0.5541            5.94s\n",
      "       400           0.5535            5.88s\n",
      "       401           0.5529            5.82s\n",
      "       402           0.5523            5.76s\n",
      "       403           0.5515            5.70s\n",
      "       404           0.5507            5.64s\n",
      "       405           0.5499            5.58s\n",
      "       406           0.5494            5.52s\n",
      "       407           0.5488            5.46s\n",
      "       408           0.5481            5.40s\n",
      "       409           0.5472            5.35s\n",
      "       410           0.5466            5.29s\n",
      "       411           0.5462            5.23s\n",
      "       412           0.5457            5.17s\n",
      "       413           0.5453            5.11s\n",
      "       414           0.5445            5.05s\n",
      "       415           0.5438            5.00s\n",
      "       416           0.5432            4.94s\n",
      "       417           0.5426            4.88s\n",
      "       418           0.5421            4.82s\n",
      "       419           0.5414            4.76s\n",
      "       420           0.5407            4.70s\n",
      "       421           0.5406            4.64s\n",
      "       422           0.5406            4.58s\n",
      "       423           0.5399            4.52s\n",
      "       424           0.5392            4.46s\n",
      "       425           0.5389            4.40s\n",
      "       426           0.5384            4.34s\n",
      "       427           0.5380            4.29s\n",
      "       428           0.5377            4.23s\n",
      "       429           0.5372            4.17s\n",
      "       430           0.5368            4.11s\n",
      "       431           0.5360            4.05s\n",
      "       432           0.5357            3.99s\n",
      "       433           0.5356            3.93s\n",
      "       434           0.5348            3.87s\n",
      "       435           0.5341            3.81s\n",
      "       436           0.5334            3.75s\n",
      "       437           0.5327            3.69s\n",
      "       438           0.5319            3.63s\n",
      "       439           0.5314            3.58s\n",
      "       440           0.5306            3.52s\n",
      "       441           0.5303            3.46s\n",
      "       442           0.5297            3.40s\n",
      "       443           0.5292            3.34s\n",
      "       444           0.5288            3.28s\n",
      "       445           0.5282            3.22s\n",
      "       446           0.5276            3.16s\n",
      "       447           0.5272            3.10s\n",
      "       448           0.5266            3.05s\n",
      "       449           0.5261            2.99s\n",
      "       450           0.5253            2.93s\n",
      "       451           0.5247            2.87s\n",
      "       452           0.5239            2.81s\n",
      "       453           0.5234            2.75s\n",
      "       454           0.5228            2.69s\n",
      "       455           0.5220            2.63s\n",
      "       456           0.5213            2.57s\n",
      "       457           0.5205            2.51s\n",
      "       458           0.5202            2.46s\n",
      "       459           0.5193            2.40s\n",
      "       460           0.5187            2.34s\n",
      "       461           0.5180            2.28s\n",
      "       462           0.5176            2.22s\n",
      "       463           0.5168            2.16s\n",
      "       464           0.5164            2.10s\n",
      "       465           0.5157            2.05s\n",
      "       466           0.5152            1.99s\n",
      "       467           0.5147            1.93s\n",
      "       468           0.5142            1.87s\n",
      "       469           0.5135            1.81s\n",
      "       470           0.5130            1.75s\n",
      "       471           0.5122            1.69s\n",
      "       472           0.5119            1.64s\n",
      "       473           0.5114            1.58s\n",
      "       474           0.5110            1.52s\n",
      "       475           0.5104            1.46s\n",
      "       476           0.5098            1.40s\n",
      "       477           0.5093            1.34s\n",
      "       478           0.5088            1.29s\n",
      "       479           0.5081            1.23s\n",
      "       480           0.5076            1.17s\n",
      "       481           0.5070            1.11s\n",
      "       482           0.5066            1.05s\n",
      "       483           0.5057            0.99s\n",
      "       484           0.5052            0.93s\n",
      "       485           0.5048            0.88s\n",
      "       486           0.5041            0.82s\n",
      "       487           0.5033            0.76s\n",
      "       488           0.5025            0.70s\n",
      "       489           0.5019            0.64s\n",
      "       490           0.5018            0.58s\n",
      "       491           0.5011            0.53s\n",
      "       492           0.5007            0.47s\n",
      "       493           0.5002            0.41s\n",
      "       494           0.4998            0.35s\n",
      "       495           0.4993            0.29s\n",
      "       496           0.4988            0.23s\n",
      "       497           0.4983            0.17s\n",
      "       498           0.4977            0.12s\n",
      "       499           0.4973            0.06s\n",
      "       500           0.4968            0.00s\n",
      "Test F1-Score:  0.745997542572405\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimator\n",
    "clf_best = GradientBoostingClassifier(\n",
    "    verbose=3, random_state=42, n_estimators=500, max_depth=7, learning_rate=0.1\n",
    ")\n",
    "clf_best.fit(X_train, y_train)\n",
    "# Predict the target on the test data\n",
    "predictions = clf_best.predict(X_test)\n",
    "# Print Precision\n",
    "print(\"Test F1-Score: \", f1_score(y_test, predictions, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 100), max_iter=500,\n",
       "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 100), max_iter=500,\n",
       "              random_state=42, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 100), max_iter=500,\n",
       "              random_state=42, verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Costs and predict new values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 307/500 [19:01:15<11:57:28, 223.05s/trial, best loss: -0.7333144696230892]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m     70\u001b[0m algo \u001b[38;5;241m=\u001b[39m tpe\u001b[38;5;241m.\u001b[39msuggest  \u001b[38;5;66;03m# Tree of Parzen Estimators\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(space_eval(search_space, best_result))\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[22], line 23\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m f1_weighted \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1_weighted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Because fmin() tries to minimize the objective, this function must return the negative accuracy.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39mf1_weighted, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T35792\\AppData\\Local\\miniconda3\\envs\\model-engineering\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, space_eval, Trials\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    classifier_type = params[\"type\"]\n",
    "    del params[\"type\"]\n",
    "    if classifier_type == \"svm\":\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == \"randomforest\":\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif classifier_type == \"gradientboost\":\n",
    "        clf = GradientBoostingClassifier(**params)\n",
    "    elif classifier_type == \"logreg\":\n",
    "        clf = LogisticRegression(**params)\n",
    "    elif classifier_type == \"neuralnet\":\n",
    "        clf = MLPClassifier(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    f1_weighted = cross_val_score(\n",
    "        clf, X, y, cv=5, scoring=\"f1_weighted\", n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    # Because fmin() tries to minimize the objective, this function must return the negative accuracy.\n",
    "    return {\"loss\": -f1_weighted, \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "search_space = hp.choice(\n",
    "    \"classifier_type\",\n",
    "    [\n",
    "        {\n",
    "            \"type\": \"svm\",\n",
    "            \"C\": hp.lognormal(\"SVM_C\", 0, 1.0),\n",
    "            \"kernel\": hp.choice(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"randomforest\",\n",
    "            \"n_estimators\": hp.uniformint(\"random_n_estimators\", 50, 1000),\n",
    "            \"max_depth\": hp.uniformint(\"random_max_depth\", 2, 10),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"gradientboost\",\n",
    "            \"n_estimators\": hp.uniformint(\"gradient_n_estimators\", 50, 1000),\n",
    "            \"max_depth\": hp.uniformint(\"gradient_max_depth\", 2, 10),\n",
    "            \"learning_rate\": hp.uniform(\"learning_rate\", 0.1, 5),\n",
    "            \"subsample\": hp.uniform(\"subsample\", 0.1, 1.0),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"logreg\",\n",
    "            \"C\": hp.lognormal(\"LR_C\", 0, 1.0),\n",
    "            \"solver\": hp.choice(\"solver\", [\"liblinear\", \"lbfgs\"]),\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"neuralnet\",\n",
    "            \"hidden_layer_sizes\": hp.choice(\n",
    "                \"hidden_layer_sizes\",\n",
    "                [(100,), (100, 100), (100, 50, 100), (100, 50, 25, 50, 100)],\n",
    "            ),\n",
    "            \"activation\": hp.choice(\n",
    "                \"activation\", [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "trials = Trials()\n",
    "algo = tpe.suggest  # Tree of Parzen Estimators\n",
    "best_result = fmin(\n",
    "    fn=objective, space=search_space, algo=algo, max_evals=500, trials=trials\n",
    ")\n",
    "\n",
    "print(space_eval(search_space, best_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 242,\n",
       " 'spec': None,\n",
       " 'result': {'loss': -0.7333144696230892, 'status': 'ok'},\n",
       " 'misc': {'tid': 242,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'LR_C': [],\n",
       "   'SVM_C': [],\n",
       "   'activation': [242],\n",
       "   'classifier_type': [242],\n",
       "   'criterion': [],\n",
       "   'gradient_max_depth': [],\n",
       "   'gradient_n_estimators': [],\n",
       "   'hidden_layer_sizes': [242],\n",
       "   'kernel': [],\n",
       "   'learning_rate': [],\n",
       "   'random_max_depth': [],\n",
       "   'random_n_estimators': [],\n",
       "   'solver': [],\n",
       "   'subsample': []},\n",
       "  'vals': {'LR_C': [],\n",
       "   'SVM_C': [],\n",
       "   'activation': [np.int64(2)],\n",
       "   'classifier_type': [np.int64(4)],\n",
       "   'criterion': [],\n",
       "   'gradient_max_depth': [],\n",
       "   'gradient_n_estimators': [],\n",
       "   'hidden_layer_sizes': [np.int64(2)],\n",
       "   'kernel': [],\n",
       "   'learning_rate': [],\n",
       "   'random_max_depth': [],\n",
       "   'random_n_estimators': [],\n",
       "   'solver': [],\n",
       "   'subsample': []}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2024, 12, 23, 4, 23, 41, 606000),\n",
       " 'refresh_time': datetime.datetime(2024, 12, 23, 4, 24, 55, 445000)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Net was the best.\n",
    "Now trying out what performance can be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Iteration 1, loss = 0.50495431\n",
      "Iteration 2, loss = 0.50335616\n",
      "Iteration 3, loss = 0.50182613\n",
      "Iteration 4, loss = 0.50057827\n",
      "Iteration 5, loss = 0.49817145\n",
      "Iteration 6, loss = 0.49577774\n",
      "Iteration 7, loss = 0.49354350\n",
      "Iteration 8, loss = 0.49159996\n",
      "Iteration 9, loss = 0.49138260\n",
      "Iteration 10, loss = 0.49081048\n",
      "Iteration 11, loss = 0.49189025\n",
      "Iteration 12, loss = 0.49094353\n",
      "Iteration 13, loss = 0.49101285\n",
      "Iteration 14, loss = 0.49019816\n",
      "Iteration 15, loss = 0.48972166\n",
      "Iteration 16, loss = 0.48931743\n",
      "Iteration 17, loss = 0.48930077\n",
      "Iteration 18, loss = 0.48865892\n",
      "Iteration 19, loss = 0.48807047\n",
      "Iteration 20, loss = 0.48716022\n",
      "Iteration 21, loss = 0.48629797\n",
      "Iteration 22, loss = 0.48591555\n",
      "Iteration 23, loss = 0.48692030\n",
      "Iteration 24, loss = 0.48609218\n",
      "Iteration 25, loss = 0.48509262\n",
      "Iteration 26, loss = 0.48471827\n",
      "Iteration 27, loss = 0.48499878\n",
      "Iteration 28, loss = 0.48292052\n",
      "Iteration 29, loss = 0.48299832\n",
      "Iteration 30, loss = 0.48234770\n",
      "Iteration 31, loss = 0.48207507\n",
      "Iteration 32, loss = 0.48284954\n",
      "Iteration 33, loss = 0.48128007\n",
      "Iteration 34, loss = 0.48064067\n",
      "Iteration 35, loss = 0.48118970\n",
      "Iteration 36, loss = 0.48053578\n",
      "Iteration 37, loss = 0.47895267\n",
      "Iteration 38, loss = 0.47912649\n",
      "Iteration 39, loss = 0.47906388\n",
      "Iteration 40, loss = 0.47856388\n",
      "Iteration 41, loss = 0.47778224\n",
      "Iteration 42, loss = 0.47770731\n",
      "Iteration 43, loss = 0.47831033\n",
      "Iteration 44, loss = 0.47742037\n",
      "Iteration 45, loss = 0.47666806\n",
      "Iteration 46, loss = 0.47726377\n",
      "Iteration 47, loss = 0.47675833\n",
      "Iteration 48, loss = 0.47591596\n",
      "Iteration 49, loss = 0.47618762\n",
      "Iteration 50, loss = 0.47479949\n",
      "Iteration 51, loss = 0.47534519\n",
      "Iteration 52, loss = 0.47496666\n",
      "Iteration 53, loss = 0.47461900\n",
      "Iteration 54, loss = 0.47377791\n",
      "Iteration 55, loss = 0.47388512\n",
      "Iteration 56, loss = 0.47539985\n",
      "Iteration 57, loss = 0.47414609\n",
      "Iteration 58, loss = 0.47286653\n",
      "Iteration 59, loss = 0.47334528\n",
      "Iteration 60, loss = 0.47340159\n",
      "Iteration 61, loss = 0.47346224\n",
      "Iteration 62, loss = 0.47195792\n",
      "Iteration 63, loss = 0.47223635\n",
      "Iteration 64, loss = 0.47199477\n",
      "Iteration 65, loss = 0.47183995\n",
      "Iteration 66, loss = 0.47110353\n",
      "Iteration 67, loss = 0.47154253\n",
      "Iteration 68, loss = 0.47084236\n",
      "Iteration 69, loss = 0.47068044\n",
      "Iteration 70, loss = 0.47095320\n",
      "Iteration 71, loss = 0.47098581\n",
      "Iteration 72, loss = 0.47052593\n",
      "Iteration 73, loss = 0.46990588\n",
      "Iteration 74, loss = 0.46990230\n",
      "Iteration 75, loss = 0.46851822\n",
      "Iteration 76, loss = 0.46844970\n",
      "Iteration 77, loss = 0.46986170\n",
      "Iteration 78, loss = 0.46962148\n",
      "Iteration 79, loss = 0.46883838\n",
      "Iteration 80, loss = 0.46785210\n",
      "Iteration 81, loss = 0.46856136\n",
      "Iteration 82, loss = 0.46812016\n",
      "Iteration 83, loss = 0.46740733\n",
      "Iteration 84, loss = 0.46814241\n",
      "Iteration 85, loss = 0.46696616\n",
      "Iteration 86, loss = 0.46707932\n",
      "Iteration 87, loss = 0.46671701\n",
      "Iteration 88, loss = 0.46623915\n",
      "Iteration 89, loss = 0.46550221\n",
      "Iteration 90, loss = 0.46559565\n",
      "Iteration 91, loss = 0.46655109\n",
      "Iteration 92, loss = 0.46598330\n",
      "Iteration 93, loss = 0.46619583\n",
      "Iteration 94, loss = 0.46491545\n",
      "Iteration 95, loss = 0.46515165\n",
      "Iteration 96, loss = 0.46424899\n",
      "Iteration 97, loss = 0.46512741\n",
      "Iteration 98, loss = 0.46478045\n",
      "Iteration 99, loss = 0.46480762\n",
      "Iteration 100, loss = 0.46444066\n",
      "Iteration 101, loss = 0.46337520\n",
      "Iteration 102, loss = 0.46366043\n",
      "Iteration 103, loss = 0.46351354\n",
      "Iteration 104, loss = 0.46366271\n",
      "Iteration 105, loss = 0.46286049\n",
      "Iteration 106, loss = 0.46314102\n",
      "Iteration 107, loss = 0.46276607\n",
      "Iteration 108, loss = 0.46208565\n",
      "Iteration 109, loss = 0.46339537\n",
      "Iteration 110, loss = 0.46246161\n",
      "Iteration 111, loss = 0.46228635\n",
      "Iteration 112, loss = 0.46186863\n",
      "Iteration 113, loss = 0.46116518\n",
      "Iteration 114, loss = 0.46127724\n",
      "Iteration 115, loss = 0.46159116\n",
      "Iteration 116, loss = 0.46155145\n",
      "Iteration 117, loss = 0.46086082\n",
      "Iteration 118, loss = 0.46070689\n",
      "Iteration 119, loss = 0.46112635\n",
      "Iteration 120, loss = 0.46035789\n",
      "Iteration 121, loss = 0.46002340\n",
      "Iteration 122, loss = 0.45948082\n",
      "Iteration 123, loss = 0.45968062\n",
      "Iteration 124, loss = 0.46000694\n",
      "Iteration 125, loss = 0.45925354\n",
      "Iteration 126, loss = 0.45860171\n",
      "Iteration 127, loss = 0.45978814\n",
      "Iteration 128, loss = 0.45910437\n",
      "Iteration 129, loss = 0.45834891\n",
      "Iteration 130, loss = 0.45761138\n",
      "Iteration 131, loss = 0.45903021\n",
      "Iteration 132, loss = 0.45800541\n",
      "Iteration 133, loss = 0.45898326\n",
      "Iteration 134, loss = 0.45787523\n",
      "Iteration 135, loss = 0.45746710\n",
      "Iteration 136, loss = 0.45785753\n",
      "Iteration 137, loss = 0.45834850\n",
      "Iteration 138, loss = 0.45681100\n",
      "Iteration 139, loss = 0.45692561\n",
      "Iteration 140, loss = 0.45715825\n",
      "Iteration 141, loss = 0.45711329\n",
      "Iteration 142, loss = 0.45688602\n",
      "Iteration 143, loss = 0.45678137\n",
      "Iteration 144, loss = 0.45638023\n",
      "Iteration 145, loss = 0.45588511\n",
      "Iteration 146, loss = 0.45677109\n",
      "Iteration 147, loss = 0.45603322\n",
      "Iteration 148, loss = 0.45551314\n",
      "Iteration 149, loss = 0.45592395\n",
      "Iteration 150, loss = 0.45597725\n",
      "Iteration 151, loss = 0.45566583\n",
      "Iteration 152, loss = 0.45515029\n",
      "Iteration 153, loss = 0.45561645\n",
      "Iteration 154, loss = 0.45531295\n",
      "Iteration 155, loss = 0.45528792\n",
      "Iteration 156, loss = 0.45532230\n",
      "Iteration 157, loss = 0.45416727\n",
      "Iteration 158, loss = 0.45399608\n",
      "Iteration 159, loss = 0.45353496\n",
      "Iteration 160, loss = 0.45377027\n",
      "Iteration 161, loss = 0.45418596\n",
      "Iteration 162, loss = 0.45383161\n",
      "Iteration 163, loss = 0.45296463\n",
      "Iteration 164, loss = 0.45342911\n",
      "Iteration 165, loss = 0.45300807\n",
      "Iteration 166, loss = 0.45308603\n",
      "Iteration 167, loss = 0.45372623\n",
      "Iteration 168, loss = 0.45210679\n",
      "Iteration 169, loss = 0.45273969\n",
      "Iteration 170, loss = 0.45165830\n",
      "Iteration 171, loss = 0.45134602\n",
      "Iteration 172, loss = 0.45237483\n",
      "Iteration 173, loss = 0.45268648\n",
      "Iteration 174, loss = 0.45264724\n",
      "Iteration 175, loss = 0.45155242\n",
      "Iteration 176, loss = 0.45087223\n",
      "Iteration 177, loss = 0.45107622\n",
      "Iteration 178, loss = 0.45001982\n",
      "Iteration 179, loss = 0.45067467\n",
      "Iteration 180, loss = 0.45133528\n",
      "Iteration 181, loss = 0.45092843\n",
      "Iteration 182, loss = 0.45105944\n",
      "Iteration 183, loss = 0.45059880\n",
      "Iteration 184, loss = 0.45056468\n",
      "Iteration 185, loss = 0.44968222\n",
      "Iteration 186, loss = 0.44978704\n",
      "Iteration 187, loss = 0.44932496\n",
      "Iteration 188, loss = 0.44952367\n",
      "Iteration 189, loss = 0.44985988\n",
      "Iteration 190, loss = 0.44953011\n",
      "Iteration 191, loss = 0.44840204\n",
      "Iteration 192, loss = 0.44910595\n",
      "Iteration 193, loss = 0.44873910\n",
      "Iteration 194, loss = 0.44840151\n",
      "Iteration 195, loss = 0.44814992\n",
      "Iteration 196, loss = 0.44799016\n",
      "Iteration 197, loss = 0.44819725\n",
      "Iteration 198, loss = 0.44775196\n",
      "Iteration 199, loss = 0.44813862\n",
      "Iteration 200, loss = 0.44759414\n",
      "Iteration 201, loss = 0.44758786\n",
      "Iteration 202, loss = 0.44755478\n",
      "Iteration 203, loss = 0.44706128\n",
      "Iteration 204, loss = 0.44676995\n",
      "Iteration 205, loss = 0.44669453\n",
      "Iteration 206, loss = 0.44727987\n",
      "Iteration 207, loss = 0.44655731\n",
      "Iteration 208, loss = 0.44664440\n",
      "Iteration 209, loss = 0.44718044\n",
      "Iteration 210, loss = 0.44641211\n",
      "Iteration 211, loss = 0.44615452\n",
      "Iteration 212, loss = 0.44583393\n",
      "Iteration 213, loss = 0.44585130\n",
      "Iteration 214, loss = 0.44579165\n",
      "Iteration 215, loss = 0.44510351\n",
      "Iteration 216, loss = 0.44589347\n",
      "Iteration 217, loss = 0.44486241\n",
      "Iteration 218, loss = 0.44573277\n",
      "Iteration 219, loss = 0.44526334\n",
      "Iteration 220, loss = 0.44494402\n",
      "Iteration 221, loss = 0.44478359\n",
      "Iteration 222, loss = 0.44457420\n",
      "Iteration 223, loss = 0.44515098\n",
      "Iteration 224, loss = 0.44441650\n",
      "Iteration 225, loss = 0.44430462\n",
      "Iteration 226, loss = 0.44379676\n",
      "Iteration 227, loss = 0.44400267\n",
      "Iteration 228, loss = 0.44298561\n",
      "Iteration 229, loss = 0.44370437\n",
      "Iteration 230, loss = 0.44366050\n",
      "Iteration 231, loss = 0.44326858\n",
      "Iteration 232, loss = 0.44301549\n",
      "Iteration 233, loss = 0.44313516\n",
      "Iteration 234, loss = 0.44316501\n",
      "Iteration 235, loss = 0.44337627\n",
      "Iteration 236, loss = 0.44340158\n",
      "Iteration 237, loss = 0.44197242\n",
      "Iteration 238, loss = 0.44230440\n",
      "Iteration 239, loss = 0.44204233\n",
      "Iteration 240, loss = 0.44164670\n",
      "Iteration 241, loss = 0.44225196\n",
      "Iteration 242, loss = 0.44187280\n",
      "Iteration 243, loss = 0.44110951\n",
      "Iteration 244, loss = 0.44089817\n",
      "Iteration 245, loss = 0.44209642\n",
      "Iteration 246, loss = 0.44120178\n",
      "Iteration 247, loss = 0.44029131\n",
      "Iteration 248, loss = 0.44130297\n",
      "Iteration 249, loss = 0.44043302\n",
      "Iteration 250, loss = 0.44078055\n",
      "Iteration 251, loss = 0.44059475\n",
      "Iteration 252, loss = 0.44049978\n",
      "Iteration 253, loss = 0.43981209\n",
      "Iteration 254, loss = 0.44063568\n",
      "Iteration 255, loss = 0.43993575\n",
      "Iteration 256, loss = 0.44030944\n",
      "Iteration 257, loss = 0.43904338\n",
      "Iteration 258, loss = 0.43991253\n",
      "Iteration 259, loss = 0.43943281\n",
      "Iteration 260, loss = 0.43930940\n",
      "Iteration 261, loss = 0.43991186\n",
      "Iteration 262, loss = 0.43885697\n",
      "Iteration 263, loss = 0.43837046\n",
      "Iteration 264, loss = 0.43886726\n",
      "Iteration 265, loss = 0.43801965\n",
      "Iteration 266, loss = 0.43916958\n",
      "Iteration 267, loss = 0.43817526\n",
      "Iteration 268, loss = 0.43932486\n",
      "Iteration 269, loss = 0.43789390\n",
      "Iteration 270, loss = 0.43816448\n",
      "Iteration 271, loss = 0.43754431\n",
      "Iteration 272, loss = 0.43821272\n",
      "Iteration 273, loss = 0.43746947\n",
      "Iteration 274, loss = 0.43726800\n",
      "Iteration 275, loss = 0.43811614\n",
      "Iteration 276, loss = 0.43665209\n",
      "Iteration 277, loss = 0.43735856\n",
      "Iteration 278, loss = 0.43679139\n",
      "Iteration 279, loss = 0.43720673\n",
      "Iteration 280, loss = 0.43754998\n",
      "Iteration 281, loss = 0.43676246\n",
      "Iteration 282, loss = 0.43602876\n",
      "Iteration 283, loss = 0.43601811\n",
      "Iteration 284, loss = 0.43602482\n",
      "Iteration 285, loss = 0.43557012\n",
      "Iteration 286, loss = 0.43553947\n",
      "Iteration 287, loss = 0.43548888\n",
      "Iteration 288, loss = 0.43602726\n",
      "Iteration 289, loss = 0.43527028\n",
      "Iteration 290, loss = 0.43560576\n",
      "Iteration 291, loss = 0.43590193\n",
      "Iteration 292, loss = 0.43579605\n",
      "Iteration 293, loss = 0.43497801\n",
      "Iteration 294, loss = 0.43464841\n",
      "Iteration 295, loss = 0.43466437\n",
      "Iteration 296, loss = 0.43538273\n",
      "Iteration 297, loss = 0.43559221\n",
      "Iteration 298, loss = 0.43441079\n",
      "Iteration 299, loss = 0.43514673\n",
      "Iteration 300, loss = 0.43413887\n",
      "Iteration 301, loss = 0.43489766\n",
      "Iteration 302, loss = 0.43459150\n",
      "Iteration 303, loss = 0.43450088\n",
      "Iteration 304, loss = 0.43409748\n",
      "Iteration 305, loss = 0.43373112\n",
      "Iteration 306, loss = 0.43279456\n",
      "Iteration 307, loss = 0.43364119\n",
      "Iteration 308, loss = 0.43350482\n",
      "Iteration 309, loss = 0.43351899\n",
      "Iteration 310, loss = 0.43269155\n",
      "Iteration 311, loss = 0.43304760\n",
      "Iteration 312, loss = 0.43337742\n",
      "Iteration 313, loss = 0.43334048\n",
      "Iteration 314, loss = 0.43296860\n",
      "Iteration 315, loss = 0.43279401\n",
      "Iteration 316, loss = 0.43258378\n",
      "Iteration 317, loss = 0.43264280\n",
      "Iteration 318, loss = 0.43174600\n",
      "Iteration 319, loss = 0.43264937\n",
      "Iteration 320, loss = 0.43237636\n",
      "Iteration 321, loss = 0.43243633\n",
      "Iteration 322, loss = 0.43159629\n",
      "Iteration 323, loss = 0.43205421\n",
      "Iteration 324, loss = 0.43148873\n",
      "Iteration 325, loss = 0.43210239\n",
      "Iteration 326, loss = 0.43136221\n",
      "Iteration 327, loss = 0.43115596\n",
      "Iteration 328, loss = 0.43196220\n",
      "Iteration 329, loss = 0.43147610\n",
      "Iteration 330, loss = 0.43122039\n",
      "Iteration 331, loss = 0.43076272\n",
      "Iteration 332, loss = 0.43045580\n",
      "Iteration 333, loss = 0.43167981\n",
      "Iteration 334, loss = 0.43020133\n",
      "Iteration 335, loss = 0.43102237\n",
      "Iteration 336, loss = 0.43130569\n",
      "Iteration 337, loss = 0.43144459\n",
      "Iteration 338, loss = 0.42958144\n",
      "Iteration 339, loss = 0.43054026\n",
      "Iteration 340, loss = 0.43082552\n",
      "Iteration 341, loss = 0.42977502\n",
      "Iteration 342, loss = 0.42982556\n",
      "Iteration 343, loss = 0.43039618\n",
      "Iteration 344, loss = 0.43116186\n",
      "Iteration 345, loss = 0.42972892\n",
      "Iteration 346, loss = 0.43022138\n",
      "Iteration 347, loss = 0.42890617\n",
      "Iteration 348, loss = 0.42943691\n",
      "Iteration 349, loss = 0.42905478\n",
      "Iteration 350, loss = 0.42947162\n",
      "Iteration 351, loss = 0.42898121\n",
      "Iteration 352, loss = 0.42839321\n",
      "Iteration 353, loss = 0.42917539\n",
      "Iteration 354, loss = 0.42860169\n",
      "Iteration 355, loss = 0.42894100\n",
      "Iteration 356, loss = 0.42917177\n",
      "Iteration 357, loss = 0.42918362\n",
      "Iteration 358, loss = 0.42905257\n",
      "Iteration 359, loss = 0.42901107\n",
      "Iteration 360, loss = 0.42809650\n",
      "Iteration 361, loss = 0.42815209\n",
      "Iteration 362, loss = 0.42863069\n",
      "Iteration 363, loss = 0.42772313\n",
      "Iteration 364, loss = 0.42854680\n",
      "Iteration 365, loss = 0.42895362\n",
      "Iteration 366, loss = 0.42718092\n",
      "Iteration 367, loss = 0.42904321\n",
      "Iteration 368, loss = 0.42729577\n",
      "Iteration 369, loss = 0.42727906\n",
      "Iteration 370, loss = 0.42786314\n",
      "Iteration 371, loss = 0.42739777\n",
      "Iteration 372, loss = 0.42649923\n",
      "Iteration 373, loss = 0.42816432\n",
      "Iteration 374, loss = 0.42791046\n",
      "Iteration 375, loss = 0.42708166\n",
      "Iteration 376, loss = 0.42653383\n",
      "Iteration 377, loss = 0.42657747\n",
      "Iteration 378, loss = 0.42650625\n",
      "Iteration 379, loss = 0.42621528\n",
      "Iteration 380, loss = 0.42716785\n",
      "Iteration 381, loss = 0.42664760\n",
      "Iteration 382, loss = 0.42669339\n",
      "Iteration 383, loss = 0.42633147\n",
      "Iteration 384, loss = 0.42613265\n",
      "Iteration 385, loss = 0.42619414\n",
      "Iteration 386, loss = 0.42680353\n",
      "Iteration 387, loss = 0.42590496\n",
      "Iteration 388, loss = 0.42594976\n",
      "Iteration 389, loss = 0.42490980\n",
      "Iteration 390, loss = 0.42589397\n",
      "Iteration 391, loss = 0.42572654\n",
      "Iteration 392, loss = 0.42516932\n",
      "Iteration 393, loss = 0.42606347\n",
      "Iteration 394, loss = 0.42493982\n",
      "Iteration 395, loss = 0.42428392\n",
      "Iteration 396, loss = 0.42518163\n",
      "Iteration 397, loss = 0.42578198\n",
      "Iteration 398, loss = 0.42533770\n",
      "Iteration 399, loss = 0.42514806\n",
      "Iteration 400, loss = 0.42506208\n",
      "Iteration 401, loss = 0.42529968\n",
      "Iteration 402, loss = 0.42547127\n",
      "Iteration 403, loss = 0.42498726\n",
      "Iteration 404, loss = 0.42457376\n",
      "Iteration 405, loss = 0.42573889\n",
      "Iteration 406, loss = 0.42344596\n",
      "Iteration 407, loss = 0.42510771\n",
      "Iteration 408, loss = 0.42451703\n",
      "Iteration 409, loss = 0.42422335\n",
      "Iteration 410, loss = 0.42407621\n",
      "Iteration 411, loss = 0.42354355\n",
      "Iteration 412, loss = 0.42386316\n",
      "Iteration 413, loss = 0.42357769\n",
      "Iteration 414, loss = 0.42410424\n",
      "Iteration 415, loss = 0.42351625\n",
      "Iteration 416, loss = 0.42365331\n",
      "Iteration 417, loss = 0.42329543\n",
      "Iteration 418, loss = 0.42423763\n",
      "Iteration 419, loss = 0.42363237\n",
      "Iteration 420, loss = 0.42382027\n",
      "Iteration 421, loss = 0.42290972\n",
      "Iteration 422, loss = 0.42278776\n",
      "Iteration 423, loss = 0.42277842\n",
      "Iteration 424, loss = 0.42330306\n",
      "Iteration 425, loss = 0.42323017\n",
      "Iteration 426, loss = 0.42366551\n",
      "Iteration 427, loss = 0.42337523\n",
      "Iteration 428, loss = 0.42415800\n",
      "Iteration 429, loss = 0.42234384\n",
      "Iteration 430, loss = 0.42321305\n",
      "Iteration 431, loss = 0.42306033\n",
      "Iteration 432, loss = 0.42237832\n",
      "Iteration 433, loss = 0.42270484\n",
      "Iteration 434, loss = 0.42237468\n",
      "Iteration 435, loss = 0.42276615\n",
      "Iteration 436, loss = 0.42188519\n",
      "Iteration 437, loss = 0.42222742\n",
      "Iteration 438, loss = 0.42149147\n",
      "Iteration 439, loss = 0.42192163\n",
      "Iteration 440, loss = 0.42213642\n",
      "Iteration 441, loss = 0.42247628\n",
      "Iteration 442, loss = 0.42227915\n",
      "Iteration 443, loss = 0.42177077\n",
      "Iteration 444, loss = 0.42253202\n",
      "Iteration 445, loss = 0.42039275\n",
      "Iteration 446, loss = 0.42167385\n",
      "Iteration 447, loss = 0.42202102\n",
      "Iteration 448, loss = 0.42101672\n",
      "Iteration 449, loss = 0.42101564\n",
      "Iteration 450, loss = 0.42222789\n",
      "Iteration 451, loss = 0.42235117\n",
      "Iteration 452, loss = 0.42100409\n",
      "Iteration 453, loss = 0.42083717\n",
      "Iteration 454, loss = 0.42087413\n",
      "Iteration 455, loss = 0.42096342\n",
      "Iteration 456, loss = 0.42179970\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (100, 100), 'learning_rate': 'constant'}\n"
     ]
    }
   ],
   "source": [
    "# Initialisierung und Training des Neural Net\n",
    "clf = MLPClassifier(random_state=42, verbose=True, max_iter=500)\n",
    "\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(100,), (100, 100), (100, 50, 100), (100, 50, 25, 50, 100)],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "}\n",
    "\n",
    "\n",
    "CV_rfc = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_weighted\",\n",
    ")\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1-Score:  0.7413390140785745\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimator\n",
    "clf_best = CV_rfc.best_estimator_\n",
    "# Predict the target on the test data\n",
    "predictions = clf_best.predict(X_test)\n",
    "# Print Precision\n",
    "print(\"Test F1-Score: \", f1_score(y_test, predictions, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importances = best_random_forest.feature_importances_\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(range(X.shape[1]), importances, align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X_train.columns, rotation=45, fontsize=14)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.savefig(\"../Visualisierungen/Feature_Importance.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
